[
  {
    "id": "hypergrad",
    "category": "Machine Learning",
    "name": "Hypergrad",
    "organization": "CS 6787",
    "short description": "Implementation on Maclaurin's gradient-based approach for optimizing hyperparameters, where the loss function is differentiated with respect to the hyperparameters at each up- date step.",
    "long description": "Current machine learning literature propose sev- eral methods for hyperparameter search, which is a critical process significantly affecting a model’s test performance. The most popular methods to- day are random search, grid search, Bayesian optimization, and sequential model-based opti- mization. However, despite how hyperparam- eters are manually chosen and tuned in a way similar to model parameters optimization, hyper- parameter search remains vastly different from how model parameters are optimized. Hence, we build on Maclaurin’s (Maclaurin et al., 2015) gradient-based approach for optimizing hyperpa- rameters, where the loss function is differentiated with respect to the hyperparameters at each up- date step. We then compare performance and other system metrics with existing tuning meth- ods. While Maclaurin developed autograd — an automatic differentiation library — to implement this algorithm, we opt to use PyTorch’s automatic differentiation capabilities. For a logistic regres- sion model trained on MNIST, gradient-based hy- perparameter optimization had an decreased after 8-10 meta-iterations running on 2 epochs each. This approach also saw a 63MiB increase in mem- ory usage, as well as more than 10x increase in average iteration time as compared to random and grid search. These results show that a gradient descent approach is viable for optimizing both the weights of a model and its hyperparameters, and should be further examined.",
    "project duration": "1 month",
    "my role": "Data Scientist",
    "date": "Dec 2019",
    "status": "Completed",
    "project stack": "Python, PyTorch",
    "links": {
      "Download the paper": "/static/pdfs/maclaurin-download.pdf",
      "Read our report": "/static/pdfs/hypergrad-download.pdf"
    },
    "images": ["static/images/original-paper.png", "static/images/hypergrad.png"]
  },
  {
    "id": "indigo",
    "category": "Full-Stack",
    "name": "Indigo",
    "organization": "CUAir",
    "short description": "A web application to automate the process of donating to CUAir.",
    "long description": "A node.js application that allows CUAir Design and Operations members and Company Representatives to interact in a streamline way. Allowing company reps to request information, view updates on the aircraft and team, and keep up to date on the sponsorship details.",
    "project duration": "10-11 months",
    "my role": "Full-stack Developer",
    "date": "Jan 2019",
    "status": "In Progress",
    "project stack": "Node.js, MySQL, Javascript, Google API, HTML, CSS",
    "links": {
      "Check this out": "href",
      "View the code": "href"
    },
    "images": ["static/images/indigo.gif"]
  },
  {
    "id": "cuair-website",
    "category": "Front-end",
    "name": "CUAir Website",
    "organization": "CUAir",
    "short description": "Project team's responsive and data-driven website.",
    "long description": "Redesigned the website with a better understanding of how to brand CUAir with a new focus on making the website data-driven because most of the information on our website is iterative: members, sponsors, previous aircrafts, alumni, etc and made most html generated by javascript and used libraries like jQuery and d3.",
    "project duration": "2 months",
    "my role": "Website Developer and Designer",
    "date": "Aug. 2018",
    "status": "Complete",
    "project stack": "Javascript, Adobe XD, d3.js, HTML, CSS, UI/UX Design",
    "links": {
      "Check this out": "http://cuair.org/"
    },
    "images": ["static/images/cuair-website.png"]
  },
  {
    "id": "neighborhood",
    "category": "Data",
    "name": "The Perfect Neigborhood",
    "organization": "CS 4300",
    "short description": "Manhattan Neighborhood Recommender by appling Natural Language Processing on social and contextual data.",
    "long description": "Worked on a Manhattan Neighborhood Recommender which based on a user's input (e.g. budget, work location, commute, keywords such as trendy, boba, chic) recommends the best neighborhoods. In order to do this, we had to apply text mining, natural language processing, and machine learning techniques and methods in order to score the neighborhoods appropriately. I had to develop a Machine Learning model that could provide similar words e.g. boba returns bubble, tea, chai, and latte since boba wasn't in our original neighborhood description/reviews corpus. This worked effectively given that I trained the Word2Vec model using 90,000 lines of Reddit review data and the rest was our actual testing data. We also got recognition for this project and are featured in the Hall of Fame 2020 for the class.",
    "project duration": "2 months",
    "my role": "Front-end Developer, Designer, and Data Scientist",
    "date": "May. 2020",
    "status": "Complete",
    "project stack": "Python, Flask, Javascript, HTML, CSS",
    "links": {
      "Check this out": "https://theperfectneighborhood-ex.herokuapp.com/",
      "View the code": "https://github.com/llistephanie/cs4300sp2020-sc2524-kyh24-rdz26-sk2279-szk4"
    },
    "quirks": ["<img src='https://img.icons8.com/material-outlined/24/000000/merge-git.png'/> 114 commits"],
    "images": ["static/images/neighborhood-fe.png", "static/images/tpn2.gif"]
  },
  {
    "id": "travelnode",
    "category": "Full-Stack",
    "name": "travelNode",
    "organization": "Hackathon",
    "short description": "Generates the most time and cost-efficient itenerary for a given set of POIs. ",
    "long description": "Full-stack application that approaches the issue of developing the ideal itenirary in a short period of time and low budget using Djikstra's and Max-Flow Min-Cut algorithms.",
    "project duration": "36 hours",
    "my role": "Project Lead and Developer",
    "date": "Feb. 2018",
    "status": "Complete",
    "project stack": "Python, Flask, Google API, Uber API, HTML, CSS",
    "links": {
      "View the code": "https://github.com/shirleykabir/travelNode"
    },
    "images": ["static/images/travelnode.png", "static/images/travel.gif"]
  },
  {
    "id": "pix2vox",
    "category": "Machine Learning",
    "name": "Pix2Vox",
    "organization": "Space System Design Studio",
    "short description": "Application of transfered learning of a 3d reconstruction model based on query viewpoints.",
    "long description": "The goal of the model was to take in the images from the output of the Graph Query Network which provides reconstructions of the Shepard Metzler Five Parts dataset from any number of query points. Pix2Vox has an architecture made up of encoder, decoder, merger, and fuser models. The encoder/decoder returns coarse 3D volumes from multiple input images in a parallel in order to speed up the process. The context-aware fusion (merger) model selects the high-quality recon-structions from all of the coarse volumes and returns a fused 3D volume. One of the reasons why this model performs so well is that it is one of the first models which takes account of the context of the multi-view images when fusing them together. The merger model creates a score map for each coarse volume and then fuses them into one volume by the weighted sum of all coarse volumes with respect to their score maps. The figure demonstrates how the course volumes are scored and fused accordingly. This works really well with multi-view images because it preserves the spatial information of all the voxels. Lastly, the refiner model corrects wrongly recovered parts using U-net connections.\n I integrated the pre-trained 3d reconstruction model into the existing GQN implementation and pipeline. I initially ran the Pix2Vox model on the context images which is also passed into the GQN and generated a volume to see how well Pix2Vox works on unseen data. Although it was able to form a shape there were a lot of gaps which made it unclear what the general shape looked like. Pix2Vox performed really well on the ShapeNet dataset so I looked into the ShapeNet dataset to see if it had to do with the image quality or certain attributes. The ShapeNet dataset has almost twice as large images, has a transparent background which is switched to black using data transformations which helps the actual items stand out much more from the background color - accentuating the general shape of the object. Since the ShepardMetzler is much blurrier than ShapeNet I set a threshold so for example, if any of the RGB values are <0.6 it is automatically set to 0 so that it can have a stronger contrast and borders for the Pix2Vox model to pick up on. Figure is an example of ShapeNet image data.\nThese images demonstrate how the current pipeline functions. The query/reconstruction and context/query images are pre-existing. The tensorboard shows the volumes of pre-query which is just the context images and post-query which is a combination of all the context images and reconstructed images from 2000 query points with a variety of pitch and yaw values. Increasing the number of context images and reconstructed query images noticeably improves the volume and in the example a general idea of the shape is still maintained by keeping an L-shape.",
    "project duration": "3 months",
    "my role": "Machine Learning Researcher",
    "date": "May. 2020",
    "status": "Complete",
    "project stack": "PyTorch, Python, Google Colab",
    "links": {
      "Download the paper": "/static/pdfs/pix2vox-download.pdf"
    },
    "images": ["static/images/pix2voxpaper1.png", "static/images/pix2vox.png"]
  },
  {
    "id": "pacai",
    "category": "Machine Learning",
    "name": "PacAI",
    "organization": "CS 4701",
    "short description": "A neural network that can learn how to play pac-man using a genetic algorithm.",
    "long description": "For our CS 4701 final project, we  explored Machine Learning and Evolutionary Algorithms based techniques, specifically taking a closer lookinto Neural Networks and Genetic Algorithms for the decision making of a pac-man bot. We wanted to develop a pacman version of this project called SnakeAI which implemented implemented a neural network for each snake to play and eventually learn how to play the game better. Our goal is to create an artificial intelligence system which can play as Pac-Man. A game bot which can take decisions of which direction to move in given some input information from the game such as distance from the ghosts, wall directions etc. In order to process these variety of inputs which clearly have a non-linear relationship defining the output we went ahead with Neural Network as the learning model. Neural Network has a set of weights in which are updated in order to map the relationship between inputs and output in a way which has least error.>We found an open source implementation of Pac-Man in Python using PyGame module. The implementation required keyboard inputs from the user for the Pac-Man to move.<br>We used this as the base code and developed own implementation of an AI-enabled game where a neural network optimized using genetic algorithms will play the game.<br>We had to continously train this neural network times in order to learn how to play the game effectively. But before training we had to engineer input features which need to be fed to the network.We drew inspirations from what we as human players use as information before deciding which direction to move in.<br> We considered distance from ghosts, from which directions the ghosts are coming from, is there a wall next to me and the remaining food.<br>We extracted this information and engineered our features as:<br>  1) Direction from which Ghost is coming as a one hot vector  [0, 1, 0, 0] representing [Right, Left, Up, Down]<br>  2) Normalized Euclidean Distance from Ghosti<br>  3) Walls Direction (whether a wall is present in the 4 directions) [1, 1, 0, 1] representing [Right, Left, Up, Down]<br>  4) Normalized Euclidean Distance from Closest Pelete<br>  5) Normalized Euclidean Distance from Closest Energizer ",
    "project duration": "1-2 months",
    "my role": "Full-stack Developer",
    "date": "Feb. 2019",
    "status": "In Progress",
    "project stack": "React.js, HTML, CSS, SDLC",
    "links": {
      "Referenced Paper": "https://medium.com/analytics-vidhya/understanding-genetic-algorithms-in-the-artificial-intelligence-spectrum-7021b7cc25e7",
      "View the code": "https://github.coecis.cornell.edu/szk4/cs4701final"
    },
    "images": ["static/images/pacai.gif","static/images/genetic.gif"]
  },
  {
    "id": "clue",
    "category": "Full-Stack",
    "name": "Cornell Clue",
    "organization": "CS 3110",
    "short description": "Developed Clue in OCaml and used jsofocaml library to make the gui and generated heuristics for opponent stategy.",
    "long description": "N/a",
    "project duration": "1-2 months",
    "my role": "OCaml and Front-end Developer",
    "date": "May. 2018",
    "status": "Complete",
    "project stack": "OCaml, Javascript",
    "links": {
      "Check this out": "https://shirleykabir.github.io/cs3110finalproject/",
      "View the OCaml code": "https://github.coecis.cornell.edu/szk4/cs3110-finalproject",
      "View the Javascript code": "https://github.coecis.cornell.edu/szk4/cs4701final"
    },
    "quirks": ["<img src='https://img.icons8.com/material-outlined/24/000000/merge-git.png'/> 68 commits"],
    "images": ["static/images/clue.gif"]
  }
]
